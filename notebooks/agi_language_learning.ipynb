{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# AGI Brain - Language Learning from Scratch\n\n**A spiking neural network that learns to understand and speak without any pre-trained models.**\n\nThis notebook demonstrates:\n- 100K-1M neuron sparse SNN architecture (scalable)\n- Phoneme recognition through STDP\n- Semantic memory for word associations\n- Speech synthesis from neural activity\n- Learning from YouTube videos and web pages\n\n---\n\n**Runtime Setup:** Go to `Runtime > Change runtime type > T4 GPU`"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies and clone repository\n!pip install tensorflow numpy matplotlib scipy gradio yt-dlp librosa --quiet\n\n# Clone fresh repository (ensures latest code)\n%cd /content\n!rm -rf agi-brain\n!git clone https://github.com/jeebus87/agi-brain.git\n%cd agi-brain\n\nimport sys\nsys.path.insert(0, '/content/agi-brain')\n\nprint(\"Setup complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs available:\", gpus)\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nSetup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 1.5 Brain Persistence (Google Drive)\n\nSave your brain to Google Drive so you don't have to retrain every session!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Mount Google Drive for persistent storage\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Set up persistence\nfrom src.interface.brain_persistence import BrainPersistence\n\nBRAIN_NAME = \"my_agi_brain\"  # Change this to use different saves\npersistence = BrainPersistence()\n\n# Check for existing saves\nsaves = persistence.list_saves()\nif saves:\n    print(\"\\nExisting brain saves found:\")\n    for name, info in saves.items():\n        print(f\"  - {name}: {info.get('vocabulary_size', 0)} words, saved {info.get('saved_at', 'unknown')}\")\nelse:\n    print(\"\\nNo existing saves found. Will create new brain.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Sparse SNN Architecture\n\nMemory-efficient architecture using sparse connectivity:\n- **Free Colab Tier:** 100K neurons (~0.2 GB)\n- **Colab Pro:** 500K-1M neurons (~1-4 GB)\n- Event-driven computation\n- Population-level parallelism"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.language.sparse_network import estimate_memory\n\n# Check memory requirements\nprint(\"Memory Estimates (0.1% connectivity):\")\nprint(\"=\" * 50)\nfor n in [100_000, 500_000, 1_000_000]:\n    est = estimate_memory(n, connectivity=0.001)\n    fits = \"YES\" if est['total_gb'] < 10 else \"NO\"\n    print(f\"{n/1e6:.1f}M neurons: {est['total_gb']:.2f} GB (fits Colab: {fits})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from src.language.sparse_network import create_language_brain\n\n# Create the language brain (100K neurons for free Colab tier)\n# Scale up to 500K-1M if you have Colab Pro\nprint(\"Creating language brain...\")\nbrain_snn = create_language_brain(n_neurons=100_000, use_gpu=True)\n\nprint(f\"\\nTotal neurons: {brain_snn.total_neurons():,}\")\nprint(f\"Memory usage: {brain_snn.memory_usage_mb():.1f} MB\")\nprint(f\"Populations: {len(brain_snn.populations)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Audio Encoding (Cochlea Simulation)\n",
    "\n",
    "Converts audio waveforms to spike patterns, mimicking biological cochlea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.language.audio_encoder import CochleaEncoder, AudioProcessor\n",
    "\n",
    "# Create cochlea encoder\n",
    "cochlea = CochleaEncoder()\n",
    "\n",
    "# Generate test audio (speech-like frequency sweep)\n",
    "sample_rate = 16000\n",
    "duration = 1.0\n",
    "t = np.linspace(0, duration, int(sample_rate * duration))\n",
    "\n",
    "# Simulated vowel (formants at 700Hz, 1200Hz, 2500Hz)\n",
    "f0 = 120  # Fundamental frequency\n",
    "audio = np.zeros_like(t)\n",
    "for harmonic in range(1, 20):\n",
    "    freq = f0 * harmonic\n",
    "    # Apply formant filter (simplified)\n",
    "    amp = np.exp(-((freq - 700)**2) / (2 * 100**2))  # F1\n",
    "    amp += np.exp(-((freq - 1200)**2) / (2 * 150**2))  # F2\n",
    "    audio += amp * np.sin(2 * np.pi * freq * t) / harmonic\n",
    "\n",
    "audio = audio / np.max(np.abs(audio)) * 0.5\n",
    "\n",
    "# Encode to spikes\n",
    "spikes = cochlea.encode_audio(audio)\n",
    "\n",
    "print(f\"Audio: {len(audio)} samples ({duration}s)\")\n",
    "print(f\"Spike representation: {spikes.shape} (time x frequency)\")\n",
    "print(f\"Spike density: {spikes.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cochlea output\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6))\n",
    "\n",
    "# Audio waveform\n",
    "axes[0].plot(t[:1600], audio[:1600], 'b-', linewidth=0.5)\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].set_title('Audio Waveform (100ms)', fontweight='bold')\n",
    "axes[0].set_xlim(0, 0.1)\n",
    "\n",
    "# Spike representation\n",
    "im = axes[1].imshow(spikes.T, aspect='auto', cmap='hot', extent=[0, duration, 80, 0])\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_ylabel('Frequency Band')\n",
    "axes[1].set_title('Cochlea Spike Output', fontweight='bold')\n",
    "plt.colorbar(im, ax=axes[1], label='Spike')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Phoneme Learning with STDP\n",
    "\n",
    "Learn to recognize phonemes (speech sounds) through spike-timing dependent plasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.language.phoneme_learner import PhonemeLearner, PhonemeConfig\n",
    "\n",
    "# Create phoneme learner\n",
    "config = PhonemeConfig(\n",
    "    n_input=800,           # Cochlea output size\n",
    "    n_phoneme_neurons=500, # Neurons per phoneme detector\n",
    "    n_phonemes=20,         # Number of phonemes to learn\n",
    "    learning_rate=0.005\n",
    ")\n",
    "learner = PhonemeLearner(config)\n",
    "\n",
    "print(f\"Phoneme learner created:\")\n",
    "print(f\"  Detectors: {len(learner.detectors)}\")\n",
    "print(f\"  Neurons per detector: {config.n_phoneme_neurons}\")\n",
    "print(f\"  Total neurons: {len(learner.detectors) * config.n_phoneme_neurons:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training patterns (simulating different phonemes)\n",
    "np.random.seed(42)\n",
    "n_phonemes = 10\n",
    "patterns = []\n",
    "\n",
    "for i in range(n_phonemes):\n",
    "    # Each phoneme has a distinct sparse pattern\n",
    "    pattern = np.zeros(800, dtype=np.float32)\n",
    "    # Activate different frequency regions for different phonemes\n",
    "    start = i * 60\n",
    "    pattern[start:start+80] = np.random.rand(80)\n",
    "    pattern[pattern < 0.5] = 0\n",
    "    patterns.append(pattern)\n",
    "\n",
    "print(f\"Created {len(patterns)} distinct phoneme patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train phoneme recognition\n",
    "print(\"Training phoneme recognition...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "n_epochs = 5\n",
    "samples_per_phoneme = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for phoneme_idx in range(n_phonemes):\n",
    "        for _ in range(samples_per_phoneme):\n",
    "            # Add noise to pattern\n",
    "            pattern = patterns[phoneme_idx].copy()\n",
    "            noise = np.random.rand(800).astype(np.float32) * 0.2\n",
    "            noisy_pattern = np.clip(pattern + noise, 0, 1)\n",
    "            noisy_pattern[noisy_pattern < 0.3] = 0\n",
    "            \n",
    "            # Process with supervised learning\n",
    "            detected, conf = learner.process(\n",
    "                noisy_pattern,\n",
    "                learn=True,\n",
    "                target_phoneme=phoneme_idx\n",
    "            )\n",
    "            \n",
    "            if detected == phoneme_idx:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}: Accuracy = {accuracy:.1%}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test phoneme recognition\n",
    "print(\"\\nTesting phoneme recognition:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_correct = 0\n",
    "for phoneme_idx in range(n_phonemes):\n",
    "    pattern = patterns[phoneme_idx]\n",
    "    detected, conf = learner.process(pattern, learn=False)\n",
    "    status = \"correct\" if detected == phoneme_idx else f\"wrong (got {detected})\"\n",
    "    print(f\"Phoneme {phoneme_idx}: detected {detected} (conf: {conf:.2f}) - {status}\")\n",
    "    if detected == phoneme_idx:\n",
    "        test_correct += 1\n",
    "\n",
    "print(f\"\\nTest accuracy: {test_correct}/{n_phonemes} = {test_correct/n_phonemes:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Semantic Memory\n",
    "\n",
    "Learn word-meaning associations using Sparse Distributed Memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.language.semantic_memory import SemanticMemory, SemanticConfig\n",
    "\n",
    "# Create semantic memory\n",
    "sem_config = SemanticConfig(\n",
    "    n_hard_locations=5000,\n",
    "    address_size=500,\n",
    "    data_size=500\n",
    ")\n",
    "memory = SemanticMemory(sem_config)\n",
    "\n",
    "print(\"Semantic memory created\")\n",
    "print(f\"  Hard locations: {sem_config.n_hard_locations:,}\")\n",
    "print(f\"  Vector dimensions: {sem_config.data_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teach some concepts and relationships\n",
    "print(\"Teaching concepts...\")\n",
    "\n",
    "# Create basic concepts\n",
    "concepts = [\n",
    "    \"cat\", \"dog\", \"bird\", \"fish\",\n",
    "    \"animal\", \"pet\", \"mammal\",\n",
    "    \"run\", \"fly\", \"swim\", \"walk\",\n",
    "    \"small\", \"large\", \"fast\", \"slow\"\n",
    "]\n",
    "\n",
    "for word in concepts:\n",
    "    memory.create_concept(word=word)\n",
    "\n",
    "# Learn associations\n",
    "associations = [\n",
    "    (\"cat\", \"animal\"), (\"cat\", \"pet\"), (\"cat\", \"mammal\"), (\"cat\", \"small\"),\n",
    "    (\"dog\", \"animal\"), (\"dog\", \"pet\"), (\"dog\", \"mammal\"), (\"dog\", \"run\"),\n",
    "    (\"bird\", \"animal\"), (\"bird\", \"fly\"), (\"bird\", \"small\"),\n",
    "    (\"fish\", \"animal\"), (\"fish\", \"swim\"), (\"fish\", \"pet\"),\n",
    "    (\"mammal\", \"animal\"),\n",
    "    (\"run\", \"fast\"), (\"fly\", \"fast\"), (\"swim\", \"fast\"),\n",
    "]\n",
    "\n",
    "for w1, w2 in associations:\n",
    "    memory.learn_association(w1, w2, strength=0.3)\n",
    "\n",
    "print(f\"Vocabulary: {memory.get_vocabulary_size()} words\")\n",
    "print(f\"Concepts: {len(memory.concepts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn from sentences\n",
    "sentences = [\n",
    "    [\"the\", \"cat\", \"is\", \"a\", \"small\", \"pet\"],\n",
    "    [\"the\", \"dog\", \"can\", \"run\", \"fast\"],\n",
    "    [\"birds\", \"can\", \"fly\", \"in\", \"the\", \"sky\"],\n",
    "    [\"fish\", \"swim\", \"in\", \"water\"],\n",
    "    [\"cats\", \"and\", \"dogs\", \"are\", \"mammals\"],\n",
    "    [\"pets\", \"are\", \"animals\", \"we\", \"love\"],\n",
    "]\n",
    "\n",
    "print(\"Learning from sentences...\")\n",
    "for sentence in sentences:\n",
    "    memory.learn_from_sentence(sentence)\n",
    "\n",
    "print(f\"Updated vocabulary: {memory.get_vocabulary_size()} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test spreading activation\n",
    "print(\"\\nSpreading activation from 'cat':\")\n",
    "print(\"=\" * 40)\n",
    "activations = memory.spread_activation(\"cat\", depth=2)\n",
    "for word, activation in sorted(activations.items(), key=lambda x: -x[1])[:10]:\n",
    "    bar = \"*\" * int(activation * 20)\n",
    "    print(f\"  {word:12} {activation:.3f} {bar}\")\n",
    "\n",
    "print(\"\\nSpreading activation from 'fly':\")\n",
    "print(\"=\" * 40)\n",
    "activations = memory.spread_activation(\"fly\", depth=2)\n",
    "for word, activation in sorted(activations.items(), key=lambda x: -x[1])[:10]:\n",
    "    bar = \"*\" * int(activation * 20)\n",
    "    print(f\"  {word:12} {activation:.3f} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Speech Generation\n",
    "\n",
    "Generate speech audio from neural activity using formant synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.language.speech_generator import SpeechGenerator, FormantSynthesizer\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Create speech generator\n",
    "generator = SpeechGenerator()\n",
    "\n",
    "# Test text to phonemes\n",
    "test_text = \"hello world\"\n",
    "phonemes = generator.text_to_phonemes(test_text)\n",
    "print(f\"Text: '{test_text}'\")\n",
    "print(f\"Phonemes: {' '.join(phonemes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate speech\n",
    "print(\"\\nGenerating speech...\")\n",
    "audio_output = generator.speak(test_text, speed=0.8)\n",
    "print(f\"Audio length: {len(audio_output)} samples ({len(audio_output)/16000:.2f}s)\")\n",
    "\n",
    "# Play audio (works in Colab)\n",
    "Audio(audio_output, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate different phrases\n",
    "phrases = [\n",
    "    \"cat\",\n",
    "    \"hello\", \n",
    "    \"goodbye\",\n",
    "    \"i am learning\"\n",
    "]\n",
    "\n",
    "for phrase in phrases:\n",
    "    print(f\"\\n'{phrase}':\")\n",
    "    audio = generator.speak(phrase)\n",
    "    display(Audio(audio, rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Complete AGI Brain Integration\n",
    "\n",
    "Combine all components into a unified system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class SimpleBrain:\n    \"\"\"Simplified AGI brain for demonstration.\"\"\"\n    \n    def __init__(self, semantic_mem=None, speech_gen=None):\n        # Components (use existing or create new)\n        self.semantic_memory = semantic_mem or memory\n        self.speech_generator = speech_gen or generator\n        self.phoneme_learner = learner  # From phoneme training above\n        self.conversation_history = []\n        \n    def process(self, text):\n        \"\"\"Process input and generate response.\"\"\"\n        words = text.lower().split()\n        \n        # Learn from input\n        self.semantic_memory.learn_from_sentence(words)\n        \n        # Find associations\n        all_activations = {}\n        for word in words:\n            if self.semantic_memory.lookup(word):\n                activations = self.semantic_memory.spread_activation(word, depth=2)\n                for w, a in activations.items():\n                    all_activations[w] = all_activations.get(w, 0) + a\n        \n        # Generate response\n        if all_activations:\n            top_words = sorted(all_activations.items(), key=lambda x: -x[1])[:3]\n            associated = [w for w, a in top_words if w not in words]\n            if associated:\n                response = f\"I think of {', '.join(associated)}\"\n            else:\n                response = \"Tell me more\"\n        else:\n            response = f\"Learning about {words[0] if words else 'nothing'}\"\n        \n        self.conversation_history.append((text, response))\n        return response\n    \n    def speak(self, text):\n        \"\"\"Generate speech audio.\"\"\"\n        return self.speech_generator.speak(text)\n\n# Create brain and try to load saved state\nbrain = SimpleBrain()\n\n# Try to load existing brain state\nif BRAIN_NAME in persistence.list_saves():\n    print(f\"Loading saved brain: {BRAIN_NAME}\")\n    persistence.load_brain(brain, BRAIN_NAME)\nelse:\n    print(\"Starting with fresh brain\")\n\nprint(f\"\\nBrain ready! Vocabulary: {brain.semantic_memory.get_vocabulary_size()} words\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a conversation\n",
    "print(\"Conversation with AGI Brain:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "inputs = [\n",
    "    \"hello\",\n",
    "    \"tell me about cats\",\n",
    "    \"can cats fly\",\n",
    "    \"what animals can fly\",\n",
    "    \"dogs are pets too\"\n",
    "]\n",
    "\n",
    "for user_input in inputs:\n",
    "    response = brain.process(user_input)\n",
    "    print(f\"\\nYou: {user_input}\")\n",
    "    print(f\"Brain: {response}\")\n",
    "    \n",
    "    # Generate and play audio response\n",
    "    audio = brain.speak(response)\n",
    "    display(Audio(audio, rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Learning from YouTube (Optional)\n",
    "\n",
    "Learn language from YouTube video transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if yt-dlp is available\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run(['yt-dlp', '--version'], capture_output=True)\n",
    "    print(\"yt-dlp available!\")\n",
    "    YTDLP_AVAILABLE = True\n",
    "except:\n",
    "    print(\"yt-dlp not found. Install with: !pip install yt-dlp\")\n",
    "    YTDLP_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run to learn from a YouTube video:\n",
    "# (This requires yt-dlp and may take several minutes)\n",
    "\n",
    "# from src.interface.learning_pipeline import YouTubeLearner\n",
    "# \n",
    "# learner = YouTubeLearner()\n",
    "# \n",
    "# # Example: Learn from a short educational video\n",
    "# url = \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"  # Replace with actual video\n",
    "# \n",
    "# stats = learner.learn_from_video(url, brain)\n",
    "# print(f\"Learned {stats['words_learned']} words from video!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interactive Chat (Gradio)\n",
    "\n",
    "Launch an interactive chat interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chat_with_brain(message, history):\n",
    "    response = brain.process(message)\n",
    "    return response\n",
    "\n",
    "def get_status():\n",
    "    return f\"\"\"\n",
    "    Vocabulary: {brain.semantic_memory.get_vocabulary_size()} words\n",
    "    Concepts: {len(brain.semantic_memory.concepts)}\n",
    "    Conversations: {len(brain.conversation_history)} turns\n",
    "    \"\"\"\n",
    "\n",
    "with gr.Blocks(title=\"AGI Brain\") as demo:\n",
    "    gr.Markdown(\"# AGI Brain Chat\\n\\nTalk to a neural network learning language from scratch!\")\n",
    "    \n",
    "    chatbot = gr.ChatInterface(\n",
    "        chat_with_brain,\n",
    "        examples=[\"hello\", \"tell me about cats\", \"what can fly\"],\n",
    "    )\n",
    "    \n",
    "    with gr.Accordion(\"Brain Status\", open=False):\n",
    "        status_btn = gr.Button(\"Refresh\")\n",
    "        status_text = gr.Textbox(label=\"Status\")\n",
    "        status_btn.click(get_status, outputs=status_text)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Save Brain to Google Drive\n\nSave your brain so you can continue learning next time!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Save brain to Google Drive\n# Run this cell before closing your Colab session!\n\nprint(f\"Saving brain as: {BRAIN_NAME}\")\nprint(\"=\" * 50)\n\npersistence.save_brain(brain, BRAIN_NAME)\n\nprint(\"\\n\" + \"=\" * 50)\nprint(\"Brain saved! Next time you open this notebook,\")\nprint(\"your brain will automatically load from Google Drive.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Optional: List all saved brains\nprint(\"All saved brains:\")\nprint(\"=\" * 50)\nfor name, info in persistence.list_saves().items():\n    vocab = info.get('vocabulary_size', 0)\n    concepts = info.get('concepts', 0)\n    saved = info.get('saved_at', 'unknown')\n    print(f\"  {name}:\")\n    print(f\"    Vocabulary: {vocab} words\")\n    print(f\"    Concepts: {concepts}\")\n    print(f\"    Saved: {saved}\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Summary\n\nThis notebook demonstrated:\n\n1. **Sparse SNN Architecture** - 100K neurons for free Colab, scalable to 1M+\n2. **Brain Persistence** - Save/load to Google Drive across sessions\n3. **Cochlea Encoding** - Audio to spike conversion\n4. **Phoneme Learning** - STDP-based speech sound recognition\n5. **Semantic Memory** - Word associations via Sparse Distributed Memory\n6. **Speech Generation** - Formant synthesis from neural output\n7. **Integrated Brain** - All components working together\n\n### Key Insight\n\nThis brain learns language **from scratch** - no pre-trained LLM, no transfer learning.\nIt's limited compared to ChatGPT, but it actually *learns* rather than retrieves.\n\n### Persistence Workflow\n\n1. Run all cells to train/use your brain\n2. **Before closing**: Run the \"Save Brain\" cell (Section 10)\n3. **Next session**: Your brain loads automatically from Google Drive!\n\n### Next Steps\n- Train on more data (YouTube, web, conversations)\n- Scale up neurons (Colab Pro for 500K-1M)\n- Improve phoneme-to-word mapping\n- Add reinforcement learning for conversation"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}