{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AGI Brain Simulation\n",
        "\n",
        "**Spiking Neural Network Cognitive Architecture**\n",
        "\n",
        "This notebook runs the AGI brain simulation with GPU acceleration on Google Colab.\n",
        "\n",
        "## Features\n",
        "- 125K+ neuron reasoning architecture\n",
        "- Savant-mode memory (perfect retention)\n",
        "- Neural plasticity and learning (STDP)\n",
        "- Embodied agent with navigation\n",
        "- GPU-accelerated simulation\n",
        "\n",
        "---\n",
        "\n",
        "**Runtime Setup:** Go to `Runtime > Change runtime type > T4 GPU`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install nengo nengo-spa tensorflow matplotlib numpy --quiet\n",
        "\n",
        "# Check GPU\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"GPUs available:\", gpus)\n",
        "if gpus:\n",
        "    print(\"GPU Name:\", tf.test.gpu_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!rm -rf agi-brain  # Remove if exists\n",
        "!git clone https://github.com/jeebus87/agi-brain.git\n",
        "%cd agi-brain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add to path\n",
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nengo\n",
        "import nengo_spa as spa\n",
        "\n",
        "print(\"Nengo version:\", nengo.__version__)\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Reasoning Demonstration\n",
        "\n",
        "The 100K+ neuron reasoning architecture with:\n",
        "- Working memory (savant mode)\n",
        "- Rule application engine\n",
        "- Analogy engine\n",
        "- Executive controller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='nengo_spa')\n",
        "\n",
        "from src.reasoning.poc_100k import ReasoningPOC100K, count_neurons\n",
        "\n",
        "# Create the 100K neuron POC\n",
        "print(\"Building 100K neuron reasoning architecture...\")\n",
        "poc = ReasoningPOC100K(dimensions=64)\n",
        "\n",
        "# Count neurons\n",
        "counts = count_neurons(poc)\n",
        "print(f\"\\nTotal neurons: {counts['total']:,}\")\n",
        "print(\"\\nComponents:\")\n",
        "for name, count in counts.items():\n",
        "    if name != 'total':\n",
        "        print(f\"  {name}: {count:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run a reasoning simulation\n",
        "print(\"Running reasoning simulation (5 seconds)...\")\n",
        "\n",
        "with nengo.Simulator(poc, progress_bar=True) as sim:\n",
        "    sim.run(5.0)\n",
        "\n",
        "print(\"Simulation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize reasoning activity\n",
        "t = sim.trange()\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
        "\n",
        "# Working memory\n",
        "ax1 = axes[0]\n",
        "wm_data = sim.data[poc.p_wm]\n",
        "im1 = ax1.imshow(wm_data[:, :16].T, aspect='auto', cmap='RdBu', extent=[0, t[-1], 16, 0])\n",
        "ax1.set_ylabel('Dimension')\n",
        "ax1.set_title('Working Memory State (Savant Mode)', fontweight='bold')\n",
        "plt.colorbar(im1, ax=ax1)\n",
        "\n",
        "# Rule application\n",
        "ax2 = axes[1]\n",
        "rule_data = sim.data[poc.p_rule_conclusion]\n",
        "im2 = ax2.imshow(rule_data[:, :16].T, aspect='auto', cmap='viridis', extent=[0, t[-1], 16, 0])\n",
        "ax2.set_ylabel('Dimension')\n",
        "ax2.set_title('Rule Application Output', fontweight='bold')\n",
        "plt.colorbar(im2, ax=ax2)\n",
        "\n",
        "# Response output\n",
        "ax3 = axes[2]\n",
        "response_data = sim.data[poc.p_response]\n",
        "ax3.plot(t, response_data[:, :4], alpha=0.8)\n",
        "ax3.set_xlabel('Time (seconds)')\n",
        "ax3.set_ylabel('Activity')\n",
        "ax3.set_title('Response Generator Output', fontweight='bold')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Learning Demonstration\n",
        "\n",
        "Neural plasticity using PES learning rule - the network learns to produce a specific output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple learning demo\n",
        "print(\"Creating learning network...\")\n",
        "print(\"Task: Learn to output 0.8 when input is 1.0\")\n",
        "\n",
        "with nengo.Network(seed=42) as learning_model:\n",
        "    # Constant input of 1.0\n",
        "    stim = nengo.Node(output=1.0)\n",
        "    \n",
        "    # Pre-synaptic ensemble\n",
        "    pre = nengo.Ensemble(100, dimensions=1)\n",
        "    nengo.Connection(stim, pre)\n",
        "    \n",
        "    # Post-synaptic ensemble\n",
        "    post = nengo.Ensemble(100, dimensions=1)\n",
        "    \n",
        "    # Learnable connection - starts at 0\n",
        "    conn = nengo.Connection(\n",
        "        pre, post,\n",
        "        transform=0,\n",
        "        learning_rule_type=nengo.PES(learning_rate=3e-4)\n",
        "    )\n",
        "    \n",
        "    # Error signal: target (0.8) minus actual\n",
        "    error = nengo.Node(output=lambda t, x: x - 0.8, size_in=1)\n",
        "    nengo.Connection(post, error)\n",
        "    nengo.Connection(error, conn.learning_rule)\n",
        "    \n",
        "    # Probes\n",
        "    p_post = nengo.Probe(post, synapse=0.01)\n",
        "    p_error = nengo.Probe(error, synapse=0.01)\n",
        "\n",
        "print(\"Running learning simulation (10 seconds)...\")\n",
        "with nengo.Simulator(learning_model, progress_bar=True) as sim:\n",
        "    sim.run(10.0)\n",
        "\n",
        "print(\"\\nResults:\")\n",
        "early_output = sim.data[p_post][500:1000].mean()\n",
        "late_output = sim.data[p_post][-500:].mean()\n",
        "print(f\"  Target: 0.80\")\n",
        "print(f\"  Early output (t=0.5-1s): {early_output:.3f}\")\n",
        "print(f\"  Final output (t=9.5-10s): {late_output:.3f}\")\n",
        "print(f\"  Status: {'SUCCESS!' if abs(late_output - 0.8) < 0.15 else 'Learning...'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize learning\n",
        "t = sim.trange()\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
        "\n",
        "ax1 = axes[0]\n",
        "ax1.plot(t, sim.data[p_post], label='Learned Output', linewidth=2)\n",
        "ax1.axhline(y=0.8, color='red', linestyle='--', label='Target (0.8)', linewidth=2)\n",
        "ax1.fill_between([0, 1], -0.5, 1.5, alpha=0.2, color='blue', label='Early')\n",
        "ax1.fill_between([9, 10], -0.5, 1.5, alpha=0.2, color='green', label='Late')\n",
        "ax1.set_ylabel('Output')\n",
        "ax1.set_title('Learning Progress: Output Approaches Target', fontweight='bold')\n",
        "ax1.legend(loc='right')\n",
        "ax1.set_ylim(-0.5, 1.5)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2 = axes[1]\n",
        "ax2.plot(t, sim.data[p_error], color='red', alpha=0.7)\n",
        "ax2.axhline(y=0, color='gray', linestyle='--')\n",
        "ax2.set_xlabel('Time (seconds)')\n",
        "ax2.set_ylabel('Error')\n",
        "ax2.set_title('Error Signal (approaches 0 as learning succeeds)', fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Embodied Navigation\n",
        "\n",
        "Neural agent navigating a GridWorld environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.integration.embodiment.environment import GridWorld\n",
        "from src.integration.embodiment.agent import EmbodiedAgent, AgentConfig\n",
        "\n",
        "# Create environment\n",
        "env = GridWorld(\n",
        "    size=8,\n",
        "    n_goals=1,\n",
        "    n_obstacles=5,\n",
        "    n_hazards=2,\n",
        "    vision_range=3,\n",
        "    max_steps=50,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(\"GridWorld Environment:\")\n",
        "print(env.render_ascii())\n",
        "print(\"\\nLegend: A=Agent, G=Goal, #=Wall, X=Hazard, .=Empty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create embodied agent\n",
        "config = AgentConfig(\n",
        "    vocab_dimensions=64,\n",
        "    n_neurons_per_dim=30,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "agent = EmbodiedAgent(env, config)\n",
        "print(f\"Embodied Agent: {agent.get_neuron_count():,} neurons\")\n",
        "\n",
        "# Build simulator\n",
        "agent.build_simulator(progress_bar=False)\n",
        "print(\"Agent ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run episodes\n",
        "print(\"Running navigation episodes...\\n\")\n",
        "\n",
        "results = []\n",
        "for ep in range(5):\n",
        "    env.rng = np.random.default_rng(42 + ep)\n",
        "    env._generate_grid()\n",
        "    \n",
        "    stats = agent.run_episode(max_steps=50, sim_time_per_step=0.05)\n",
        "    results.append(stats)\n",
        "    \n",
        "    status = \"SUCCESS\" if stats['success'] else \"timeout\"\n",
        "    print(f\"Episode {ep+1}: reward={stats['total_reward']:6.2f}, steps={stats['steps']:2d}, {status}\")\n",
        "\n",
        "print(f\"\\nSuccess rate: {np.mean([r['success'] for r in results])*100:.0f}%\")\n",
        "\n",
        "agent.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. GPU Acceleration Benchmark\n",
        "\n",
        "Compare CPU vs GPU performance for neural simulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.acceleration.gpu_backend import GPUAccelerator, NeuronPopulationGPU, check_gpu_available\n",
        "from src.acceleration.benchmarks import run_benchmark, compare_backends\n",
        "\n",
        "# Check GPU status\n",
        "info = check_gpu_available()\n",
        "print(\"GPU Status:\")\n",
        "print(f\"  TensorFlow: {info['tensorflow_available']}\")\n",
        "print(f\"  GPU Available: {info['gpu_available']}\")\n",
        "print(f\"  Devices: {info['gpu_devices']}\")\n",
        "print(f\"  Recommended: {info['recommended_backend']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run benchmarks\n",
        "print(\"\\nRunning performance benchmarks...\\n\")\n",
        "\n",
        "neuron_counts = [1000, 5000, 10000, 25000, 50000]\n",
        "\n",
        "results = compare_backends(\n",
        "    neuron_counts=neuron_counts,\n",
        "    dimensions=64,\n",
        "    sim_time=0.5,\n",
        "    backends=['nengo', 'gpu']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize benchmark results\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "for backend, backend_results in results.items():\n",
        "    valid = [r for r in backend_results if r]\n",
        "    if valid:\n",
        "        neurons = [r.n_neurons for r in valid]\n",
        "        rates = [r.neurons_per_second / 1e6 for r in valid]\n",
        "        ax.plot(neurons, rates, 'o-', label=backend, linewidth=2, markersize=8)\n",
        "\n",
        "ax.set_xlabel('Number of Neurons')\n",
        "ax.set_ylabel('Million Neurons/Second')\n",
        "ax.set_title('Performance Comparison: CPU vs GPU Backend', fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary\n",
        "print(\"\\nBest throughput achieved:\")\n",
        "for backend, backend_results in results.items():\n",
        "    valid = [r for r in backend_results if r]\n",
        "    if valid:\n",
        "        best = max(valid, key=lambda r: r.neurons_per_second)\n",
        "        print(f\"  {backend}: {best.neurons_per_second/1e6:.2f}M neurons/sec @ {best.n_neurons:,} neurons\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Large-Scale Simulation\n",
        "\n",
        "Simulate 100K+ neurons with GPU acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.acceleration.gpu_backend import LargeScaleSimulator\n",
        "import time\n",
        "\n",
        "# Create large-scale simulator\n",
        "print(\"Creating large-scale simulator...\")\n",
        "large_sim = LargeScaleSimulator(\n",
        "    n_populations=10,\n",
        "    neurons_per_population=10000,  # 100K total\n",
        "    dimensions=64,\n",
        "    device='auto'\n",
        ")\n",
        "\n",
        "# Create input signal\n",
        "t = np.linspace(0, 1, 1000)\n",
        "input_signal = np.sin(2 * np.pi * t)[:, np.newaxis] * np.ones(64)\n",
        "input_signal = input_signal.astype(np.float32)\n",
        "\n",
        "# Run simulation\n",
        "print(f\"\\nSimulating {large_sim.total_neurons:,} neurons for 1 second...\")\n",
        "start = time.perf_counter()\n",
        "activities = large_sim.run(input_signal, dt=0.001)\n",
        "elapsed = time.perf_counter() - start\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"  Wall time: {elapsed:.2f} seconds\")\n",
        "print(f\"  Speedup: {1.0/elapsed:.2f}x real-time\")\n",
        "print(f\"  Throughput: {large_sim.total_neurons * 1000 / elapsed / 1e6:.2f}M neuron-timesteps/sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize large-scale activity\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
        "\n",
        "# Population activity heatmap\n",
        "ax1 = axes[0]\n",
        "pop0 = activities['pop_0']\n",
        "im = ax1.imshow(pop0[:, :100].T, aspect='auto', cmap='hot', extent=[0, 1, 100, 0])\n",
        "ax1.set_xlabel('Time (seconds)')\n",
        "ax1.set_ylabel('Neuron Index')\n",
        "ax1.set_title(f'Population Activity ({large_sim.total_neurons:,} total neurons)', fontweight='bold')\n",
        "plt.colorbar(im, ax=ax1, label='Firing Rate')\n",
        "\n",
        "# Mean activity per population\n",
        "ax2 = axes[1]\n",
        "for i in range(min(5, len(activities))):\n",
        "    mean_act = np.mean(activities[f'pop_{i}'], axis=1)\n",
        "    ax2.plot(t, mean_act, label=f'Pop {i}', alpha=0.8)\n",
        "\n",
        "ax2.set_xlabel('Time (seconds)')\n",
        "ax2.set_ylabel('Mean Activity')\n",
        "ax2.set_title('Population Averages Over Time', fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **Reasoning Architecture** - 125K+ neurons with working memory, rule application, and executive control\n",
        "2. **Neural Learning** - PES-based plasticity that learns input-output mappings\n",
        "3. **Embodied Navigation** - Agent navigating GridWorld using neural perception and action\n",
        "4. **GPU Acceleration** - TensorFlow backend for high-performance simulation\n",
        "5. **Large-Scale Simulation** - 100K neurons running efficiently\n",
        "\n",
        "### Next Steps\n",
        "- Scale to 1M+ neurons with distributed simulation\n",
        "- Add more sophisticated learning (reward-modulated STDP)\n",
        "- Connect to richer environments (MuJoCo, Unity)\n",
        "- Integrate LLM for language capabilities"
      ]
    }
  ]
}
